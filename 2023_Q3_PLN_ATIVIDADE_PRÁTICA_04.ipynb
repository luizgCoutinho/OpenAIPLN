{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luizgCoutinho/OpenAIPLN/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 04 [Uso da API da OpenAI com técnicas de PLN]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 04** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/GzwCq3R7ExtE9g9a8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **26/11 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Luiz Gustavo Barros Coutinho Paiva RA: 11202020464`\n"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: 12`\n",
        "\n",
        "`Segundo capítulo: 14`\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso da **API da OpenAI** aplicando, no mínimo, 3 técnicas de PLN. As técnicas devem ser aplicadas nos 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        ">\n",
        "\n",
        "**RESTRIÇÃO**: É obrigatório usar o *endpoint* \"*`Chat Completions`*\".\n",
        "\n",
        ">\n",
        "\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   **Similaridade de Textos**\n",
        "*   **Reconhecimento de Entidades Nomeadas**\n",
        "*   **Sistemas de Perguntas e Respostas**\n",
        "\n",
        ">\n",
        "\n",
        "Os capítulos devem ser os mesmos selecionados na **ATIVIDADE PRÁTICA 02**. Para consultar os capítulos, considere a seguinte planilha:\n",
        "\n",
        ">\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC. Não é permitido alterar os capítulos já selecionados.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação as técnicas usadas e a criatividade envolvida na aplicação das mesmas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roV8OIYw6snH",
        "outputId": "a9a1f1b7-e5d7-4164-8486-3f1cf7d46a91"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalação do pacote Python da API da OpenAI\n",
        "print(f\"Instalando a biblioteca da API da OpenAI...\")\n",
        "\n",
        "!pip install openai==0.28.1\n",
        "\n",
        "print(\"API da OpenAI instalada!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeGVMLIF68rU",
        "outputId": "42420050-ac19-4730-bc5f-6937a231d464"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando a biblioteca da API da OpenAI...\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n",
            "API da OpenAI instalada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import openai\n",
        "import re\n",
        "import time\n",
        "\n",
        "# Ler a chave da API a partir do arquivo\n",
        "with open('/content/openai_chave.txt', 'r') as file:\n",
        "    chave_api = file.read()\n",
        "\n",
        "# Configurar a chave da API da OpenAI\n",
        "openai.api_key = chave_api\n",
        "\n",
        "# URLs dos capítulos do livro\n",
        "url12 = \"https://brasileiraspln.com/livro-pln/1a-edicao/parte6/cap12/cap12.html\"\n",
        "url14 = \"https://brasileiraspln.com/livro-pln/1a-edicao/parte7/cap14/cap14.html\"\n",
        "\n",
        "# Função para extrair o texto do HTML\n",
        "def extrair_texto(url):\n",
        "    response = requests.get(url, headers={'Content-Type': 'text/html; charset=utf-8'})\n",
        "    if response.status_code == 200:\n",
        "        response.encoding = 'utf-8'\n",
        "        html_content = response.text\n",
        "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "        texto = \"\"\n",
        "        for paragraph in soup.find_all([\"p\", \"h1\", \"h2\", \"h3\"]):\n",
        "            texto += paragraph.get_text() + \" \"\n",
        "        return texto\n",
        "\n",
        "# Função para remover quebras de linha\n",
        "def formatar_saida(saida):\n",
        "    return re.sub(r'^\\s+', '', saida)\n",
        "\n",
        "# Correção gramatical\n",
        "def correcao_gramatical(texto):\n",
        "    resposta = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=f\"Corrija a gramática no seguinte texto: {texto}\",\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return resposta.choices[0].text.strip()\n",
        "\n",
        "# Análise de sentimentos\n",
        "def analise_sentimentos(texto):\n",
        "    resposta = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=f\"Analise o sentimento no seguinte texto: {texto}\",\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return resposta.choices[0].text.strip()\n",
        "\n",
        "# Reconhecimento de entidades nomeadas\n",
        "def reconhecimento_entidades_nomeadas(texto):\n",
        "    resposta = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=f\"Identifique entidades nomeadas no seguinte texto: {texto}\",\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return resposta.choices[0].text.strip()\n",
        "\n",
        "# Extrair textos dos capítulos\n",
        "capitulo12 = extrair_texto(url12)\n",
        "capitulo14 = extrair_texto(url14)\n",
        "\n",
        "# Limitar o número de tokens por capítulo\n",
        "limite_tokens_por_capitulo = 4097\n",
        "capitulo12 = capitulo12[:limite_tokens_por_capitulo]\n",
        "capitulo14 = capitulo14[:limite_tokens_por_capitulo]\n",
        "\n",
        "# Aplicar técnicas nos capítulos\n",
        "# Capítulo 12\n",
        "print(\"=== Capítulo 12 ===\")\n",
        "print(\"\\nTexto Original:\")\n",
        "print(capitulo12)\n",
        "\n",
        "# Correção Gramatical\n",
        "correcao_gramatical_cap12 = correcao_gramatical(capitulo12)\n",
        "print(\"\\nCorreção Gramatical:\")\n",
        "print(formatar_saida(correcao_gramatical_cap12))\n",
        "time.sleep(20)\n",
        "\n",
        "# Análise de Sentimentos\n",
        "analise_sentimentos_cap12 = analise_sentimentos(capitulo12)\n",
        "print(\"\\nAnálise de Sentimentos:\")\n",
        "print(formatar_saida(analise_sentimentos_cap12))\n",
        "time.sleep(20)\n",
        "\n",
        "# Reconhecimento de Entidades Nomeadas\n",
        "entidades_nomeadas_cap1 = reconhecimento_entidades_nomeadas(capitulo12)\n",
        "print(\"\\nReconhecimento de Entidades Nomeadas:\")\n",
        "print(formatar_saida(entidades_nomeadas_cap1))\n",
        "time.sleep(20)\n",
        "\n",
        "# Capítulo 14\n",
        "print(\"\\n=== Capítulo 14 ===\")\n",
        "print(\"\\nTexto Original:\")\n",
        "print(capitulo14)\n",
        "\n",
        "# Correção Gramatical\n",
        "correcao_gramatical_cap14 = correcao_gramatical(capitulo14)\n",
        "print(\"\\nCorreção Gramatical:\")\n",
        "print(formatar_saida(correcao_gramatical_cap14))\n",
        "time.sleep(20)\n",
        "\n",
        "# Análise de Sentimentos\n",
        "analise_sentimentos_cap14 = analise_sentimentos(capitulo14)\n",
        "print(\"\\nAnálise de Sentimentos:\")\n",
        "print(formatar_saida(analise_sentimentos_cap14))\n",
        "time.sleep(20)\n",
        "\n",
        "# Reconhecimento de Entidades Nomeadas\n",
        "entidades_nomeadas_cap14 = reconhecimento_entidades_nomeadas(capitulo14)\n",
        "print(\"\\nReconhecimento de Entidades Nomeadas:\")\n",
        "print(formatar_saida(entidades_nomeadas_cap14))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cqqg6JXPdQK",
        "outputId": "5834ed4e-6a7c-4d13-b287-3f74d3d0a8aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Capítulo 12 ===\n",
            "\n",
            "Texto Original:\n",
            "Conteúdo 12  Resolução de Correferência Evandro Fonseca  Aline Aver Vanin  Renata Vieira  26/09/2023 PDF 12.1 Introdução No processo de construção de sentidos na língua em uso, interlocutores negociam o universo de discurso de que falam, escolhendo referir-se a algum, ou a alguns, indivíduo(s) cuja identidade estabelecem e da qual garantem a existência (Neves, 2013). Esses referentes, concretizados no texto por expressões referenciais, vão atravessá-lo por inteiro, garantindo unidade temática – isto é, a coerência que constitui um texto (Vieira; Faraco, 2019). Fazer referência a algo ou a alguém no mundo é uma ação intrinsecamente ligada à interação, em que se constituem os objetos de discurso, isto é, entidades que constituem termos das predicações, entidades oriundas de uma construção mental, e não de um mundo real (Neves, 2013). A construção de referentes se dá por cadeias de texto, redes referenciais construídas pelos objetos de discurso que constituem as marcas da textualidade. Uma cadeia de referência, ou cadeia referencial, corresponde à noção de cadeia anafórica, e cadeia coesiva (Roncarati, 2010). Os elos coesivos em um texto são mecanismos semânticos e léxico-gramaticais essenciais para a tessitura textual. Os referentes se ligam por meio de relações de sentido que formam a base para retomadas em um texto (Roncarati, 2010). Nesse sentido, as cadeias coesivas ligam referentes à(s) sua(s) expressão(ões) referencial(is), em que os fios que tecem o texto são articulados por meio de procedimentos e recursos - o que chamamos de coesão textual (Vieira; Faraco, 2019). Trata-se de elementos cujos mecanismos gramaticais coesivos estão em consonância, sejam eles por reiteração (ou retomada), por associação (ou ligações de sentidos entre as palavras presentes), ou por conexão entre as orações (por conectores) (Antunes, 2007), os quais garantem que o texto seja coerente em sua extensão. Então, se em um dado texto temos uma dada entidade, como “Maria”, nome próprio, é de se esperar que os seus referentes sejam detectados por relações léxico-semânticas do texto, como, por exemplo: por pronome, “ela”, ou por sintagma nominal, “a professora”, “a ativista”, “a mulher” etc. 12.2 Resolução de Correferência A Resolução de Correferência a partir de textos é uma tarefa útil e também um dos principais desafios da área de Processamento da Linguagem Natural (PLN). Isso porque essa tarefa depende de diversos níveis de processamento, como análise sintática, morfológica, extração de sintagmas nominais, entre outros. Na literatura, encontramos diversas iniciativas para a língua portuguesa que abordam esse problema, geralmente separados entre a resolução de anáfora (Basso, 2009; Bick, 2010; Ferradeira, 1993; Rocha, 2000; Vieira et al., 2005) e o estudo da correferência nominal (Fonseca, 2014; Fonseca; Vieira; Vanin, 2016a; Fonseca; Vieira; Vanin, 2014; Freitas et al., 2009). Resolução de Correferência consiste em identificar as diferentes formas que uma mesma menção pode assumir em um discurso. Em outras palavras, esse processo consiste em identificar determinados termos e expressões que remetem a uma mesma referência. Na sentença apresentada no Exemplo 12.1 podemos dizer que [o único país de a União Europeia a não permitir patenteamento de genes] é uma correferência de [A França], da mesma forma que [A UE] é uma correferência de [a União Europeia]. Agrupando esses termos formamos grupos de menções referenciais, mais conhecidos como cadeias de correferência. Exemplo 12.1   A França resiste como o único país de a União Europeia a não permitir patenteamento de genes. A UE … Na presente seção, veremos as definições de conceitos fortemente relacionados à tarefa de Resolução de Correferências, tais como os de referentes, entidades nomeadas, sintagmas nominais, entre outras definições. 12.2.1 Referentes Referentes, ou menções, podem ser definidos como termos os quais usamos para nos referirmos a determinada entidade em um discurso. Em um texto, essas referências podem aparecer como uma entidade nomeada específica ou como parte constituinte de um si\n",
            "\n",
            "Correção Gramatical:\n",
            "Corrija a gramática no seguinte texto:\n",
            "\n",
            "Conteúdo 12  Resolução de Correferência \n",
            "\n",
            "Evandro Fonseca, Aline Aver Vanin, Renata Vieira 26/09/2023 PDF \n",
            "\n",
            "12.1 Introdução \n",
            "\n",
            "No processo de construção de sentidos na língua em uso, interlocutores negociam o universo de discurso de que falam, escolhendo referir-se a algum, ou a alguns, indivíduos cuja identidade estabele\n",
            "\n",
            "Análise de Sentimentos:\n",
            "Positivo.\n",
            "\n",
            "Reconhecimento de Entidades Nomeadas:\n",
            "1. Evandro Fonseca\n",
            "2. Aline Aver Vanin \n",
            "3. Renata Vieira \n",
            "4. União Europeia \n",
            "5. França \n",
            "6. Neves\n",
            "7. Vieira; Faraco\n",
            "8. Roncarati\n",
            "9. Antunes\n",
            "10. Basso\n",
            "11. Bick\n",
            "12. Ferradeira\n",
            "13. Rocha\n",
            "14. Vieira et al.\n",
            "15. Fonseca; Vieira; Vanin\n",
            "16. Freitas et al.\n",
            "\n",
            "=== Capítulo 14 ===\n",
            "\n",
            "Texto Original:\n",
            "Conteúdo 14  Dataset e corpus Cláudia Freitas  26/09/2023 PDF 14.1 Introdução A preparação de bons datasets (ou corpora anotados) para o PLN é um empreendimento que costuma envolver conhecimentos variados – de computação e linguística, no mínimo. Neste capítulo, fazemos uma apresentação de conceitos básicos e metodologias relacionados à criação de datasets (ou corpora anotados)1. Afinal, se queremos avançar na área, mesmo levando em conta os grandes modelos de linguagem (LLM), precisaremos de datasets de alta qualidade, feitos para a nossa língua e cultura. Um dataset, literalmente, é um conjunto (set) de dados (data). Dados são elementos que, organizados (ou distribuídos) de uma(s) certa(s) maneira(s), isto é, tratados, produzem informação. Praticamente qualquer coisa pode ser um dado. No PLN, os dados que usamos são dados linguísticos; nossa matéria prima é a linguagem humana, e cada língua individualmente. Os dados podem ser Partindo dos exemplos acima, o elemento “palavra” pode virar um dado quando atribuímos a ele algum valor, como a sua classe gramatical (substantivo, verbo etc), classe semântica (pessoa, lugar etc), sua posição no texto ou a sua frequência. No PLN, estes valores podem ser atribuídos aos dados de duas maneiras. A primeira delas é de maneira explícita – por exemplo, com cada palavra associada a uma informação do tipo PoS (classe de palavra, do inglês, part-of-speech), sendo essa informação do tipo substantivo, verbo, pronome, advérbio etc. Ou cada frase (ou palavra) associada a uma informação do tipo polaridade de opinião, sendo essa informação do tipo positiva, negativa, neutra. No primeiro caso podemos dizer que organizamos (ou distribuímos, ou classificamos, ou rotulamos) as palavras do texto conforme sua classe morfossintática, no segundo, podemos dizer que organizamos (ou distribuímos, ou classificamos, ou rotulamos) as frases (ou palavras) do texto conforme sua polaridade. O que há em comum em ambos os casos é a organização (ou classificação) dos dados conforme classes pré-estabelecidas que nos parecem relevantes para explorar o conteúdo linguístico, e a partir delas produzimos informação: por exemplo, se há mais opiniões positivas ou negativas (ou neutras) com relação a um determinado objeto. Mas nem todo dataset com conteúdo linguístico precisa ter seus dados organizados de acordo com atributos “externos” ao texto. Grandes modelos de língua – modelos de previsão de palavras – têm como entrada imensos volumes de texto, sem informação linguística explícita associada (Capítulo 15). A informação capturada é a posição da palavra no texto e a frequência com que é usada, e isso já permite saber muito sobre as palavras, desde que tenhamos muitas delas. Mas não é deste tipo de dataset (que contém o que chamamos de textos crus) que nos ocuparemos aqui, e nem dos procedimentos que transformam posição e frequência em informação linguística, tema do Capítulo 10. Nosso foco está nos dados linguísticos que possuem alguma organização explícita humana, feita conforme classes pré-definidas por nós – dados anotados, que são elementos linguísticos que possuem classificações, anotações ou rótulos linguísticos que codificam alguma dimensão do nosso entendimento sobre as palavras, frases ou textos. Porque contêm classificações (ou análises) atribuídas aos elementos linguísticos, estes conjuntos de dados também podem ser considerados corpora anotados. 14.1.1 Dataset ou corpus anotado? Um corpus é um conjunto de dados linguísticos. A utilização de corpus – palavra latina que significa corpo e que tem como plural a palavra corpora – vem de longa data nos estudos linguísticos e lexicográficos2, e ganha força nos anos 1980 com a popularização dos computadores. A partir daí, e cada vez mais, corpus diz respeito a uma coleção de textos que pode ser processada por computadores. O material que compõe um corpus (os textos) é coletado com algum propósito (investigar ou explorar algum aspecto da linguagem, teórico ou aplicado) e foi produzido “naturalmente”, isto é, não estamos diante de frases artificialmente inventadas com o\n",
            "\n",
            "Correção Gramatical:\n",
            "objetivo de ilustrar alguma regra gramatical ou todo o léxico da língua (embora isso também seja um tipo de experimento e aqui sejamos parciais).\n",
            "Corrija a gramática no seguinte texto: \n",
            "\n",
            "Conteúdo 14  Dataset e corpus Cláudia Freitas  26/09/2023 PDF 14.1 Introdução\n",
            "A preparação de bons datasets (ou corpora anotados) para o PLN é um empreendimento que costuma envolver conhecimentos variados –\n",
            "\n",
            "Análise de Sentimentos:\n",
            "objetivo de serem usadas em experimentos, mas frases produzidas por seres humanos, em contextos e finais específicos3.\n",
            "\n",
            "Neste texto, o sentimento não é direcionado. Trata-se de um texto acadêmico, que detalha conceitos básicos e metodologias relacionados à preparação de bons datasets ou corpora anotados para o Processamento de Linguagem Natural (PLN).\n",
            "\n",
            "Reconhecimento de Entidades Nomeadas:\n",
            "propósito de serem processadas por computador.\n",
            "Entidades Nomeadas: \n",
            "Cláudia Freitas, Part-Of-Speech (PoS), polaridade de opinião, corpus anotados, conjunto de dados, dados linguísticos, textos crus, corpus.\n"
          ]
        }
      ]
    }
  ]
}